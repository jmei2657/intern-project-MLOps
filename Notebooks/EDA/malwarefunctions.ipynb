{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 13:43:15.037751: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from scipy.special import boxcox\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore_normalization(df, name):\n",
    "    mean = df[name].mean()\n",
    "    sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.drop(columns=['Name', 'md5'])\n",
    "    for i in df.columns:\n",
    "        if i != 'legitimate':\n",
    "            df[i] = boxcox(df[i], 0.5)\n",
    "            zscore_normalization(df, i)\n",
    "    correlation_matrix = df.corr()\n",
    "    cols_to_drop = []\n",
    "    for i in df.columns:\n",
    "        for j in df.columns:\n",
    "            if i != j and i != 'legitimate' and j != 'legitimate' and abs(correlation_matrix[i][j]) > 0.6 and i not in cols_to_drop and j not in cols_to_drop:\n",
    "                cols_to_drop.append(i)\n",
    "    cols_to_drop = set(cols_to_drop)\n",
    "    df.drop(columns=cols_to_drop, inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traintest_split(df):\n",
    "    X = df.drop(columns=['legitimate'])\n",
    "    y = df['legitimate']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_data):\n",
    "    with open (f'model.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    y_pred = model.predict(test_data)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(X_train, X_test, y_train, y_test):\n",
    "    model_type = \"Random Forest\"\n",
    "    print(model_type, \"classifier:\") \n",
    "    model = RandomForestClassifier()\n",
    "    start_time_train = time.time()  # Start time\n",
    "\n",
    "    model.fit(X_train, y_train)  # Fit the classifier\n",
    "        \n",
    "    end_time_train = time.time()  # End time\n",
    "    time_taken_train = end_time_train - start_time_train  # Time taken to run the code\n",
    "\n",
    "    print(f\"Time taken to train the {model_type} model: {time_taken_train} seconds\")\n",
    "        \n",
    "    # Make predictions\n",
    "    start_test = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    end_test = time.time()\n",
    "    time_taken_test = end_test - start_test  # Time taken to run the code\n",
    "\n",
    "    print(f\"Time taken to test the {model_type} model: {time_taken_test} seconds\")\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Precision:\", prec)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 score:\", f1)\n",
    "\n",
    "    with open(f'model.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(X_train, X_test, y_train, y_test):\n",
    "    model_type = \"Logistic Regression\"\n",
    "    print(model_type, \"classifier:\") \n",
    "    model = LogisticRegression(random_state=0, max_iter=1000)\n",
    "    start_time_train = time.time()  # Start time\n",
    "\n",
    "    model.fit(X_train, y_train)  # Fit the classifier\n",
    "        \n",
    "    end_time_train = time.time()  # End time\n",
    "    time_taken_train = end_time_train - start_time_train  # Time taken to run the code\n",
    "\n",
    "    print(f\"Time taken to train the {model_type} model: {time_taken_train} seconds\")\n",
    "        \n",
    "    # Make predictions\n",
    "    start_test = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    end_test = time.time()\n",
    "    time_taken_test = end_test - start_test  # Time taken to run the code\n",
    "\n",
    "    print(f\"Time taken to test the {model_type} model: {time_taken_test} seconds\")\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Precision:\", prec)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 score:\", f1)\n",
    "\n",
    "    with open(f'model.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ann(X_train, X_test, y_train, y_test):\n",
    "    input_shape = [X_train.shape[1]]\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=64, activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=1)\n",
    "    ])\n",
    "\n",
    "    model.build()\n",
    "\n",
    "    print(model.summary())\n",
    "    start_time_train = time.time()  # Start time\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mae', metrics=['accuracy'])  \n",
    "    earlystopping = callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                                mode=\"min\",\n",
    "                                                patience=5,\n",
    "                                                restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test,y_test), batch_size=256, epochs=60,callbacks=[earlystopping])\n",
    "            \n",
    "    end_time_train = time.time()  # End time\n",
    "    time_taken_train = end_time_train - start_time_train  # Time taken to run the code\n",
    "    with open(f'model.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = preprocess(df)\n",
    "    X_train, X_test, y_train, y_test = traintest_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_data):\n",
    "    with open (f'model.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    y_pred = model.predict(test_data)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(model, X, y):\n",
    "    start_time_cv = time.time() \n",
    "    \n",
    "    cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "    \n",
    "    end_time_cv = time.time()  # End time\n",
    "    time_taken_cv = end_time_cv - start_time_cv  # Time taken to run the code\n",
    "\n",
    "    print(f\"Time taken to cross-validate the model: {time_taken_cv} seconds\")\n",
    "    print(\"Cross-validation scores:\", cv_scores)\n",
    "    print(\"Mean CV accuracy:\", cv_scores.mean())\n",
    "    print(\"Standard deviation of CV accuracy:\", cv_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression classifier:\n",
      "Time taken to train the Logistic Regression model: 0.3835327625274658 seconds\n",
      "Time taken to test the Logistic Regression model: 0.004948139190673828 seconds\n",
      "Accuracy: 0.9798623687069902\n",
      "Precision: 0.9730991278712688\n",
      "Recall: 0.959196028574888\n",
      "F1 score: 0.9660975609756097\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('MalwareData.csv', sep='|')\n",
    "df = preprocess(df)\n",
    "X_train, X_test, y_train, y_test = traintest_split(df)\n",
    "train_logistic_regression(X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
