{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "485c543b-23ca-4e8d-a77e-03cca38210cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sqlalchemy\n",
      "  Using cached SQLAlchemy-2.0.31-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/site-packages (1.8.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.9/site-packages (from sqlalchemy) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/site-packages (from sqlalchemy) (3.0.3)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.17.3 in /usr/local/lib/python3.9/site-packages (from scipy) (1.21.6)\n",
      "Installing collected packages: sqlalchemy\n",
      "Successfully installed sqlalchemy-2.0.31\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e1b68a8-9819-4c77-b0f5-ac046796a43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import requests\n",
    "import pandas as pd\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from scipy.special import boxcox\n",
    "import numpy as np\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc355b0d-5ca2-4df5-8652-d19b4d40afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore_normalization(df, name):\n",
    "    mean = df[name].mean()\n",
    "    sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.drop(columns=['Name', 'md5'])\n",
    "    for i in df.columns:\n",
    "        if i != 'legitimate':\n",
    "            df[i] = boxcox(df[i], 0.5)\n",
    "            zscore_normalization(df, i)\n",
    "    correlation_matrix = df.corr()\n",
    "    cols_to_drop = []\n",
    "    for i in df.columns:\n",
    "        for j in df.columns:\n",
    "            if i != j and i != 'legitimate' and j != 'legitimate' and abs(correlation_matrix[i][j]) > 0.6 and i not in cols_to_drop and j not in cols_to_drop:\n",
    "                cols_to_drop.append(i)\n",
    "    cols_to_drop = set(cols_to_drop)\n",
    "    df.drop(columns=cols_to_drop, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a666d898-44cf-43f8-a21e-e59c0787dffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloading CSV file from GitHub...\n",
      "INFO:root:CSV file downloaded successfully.\n",
      "INFO:root:CSV file processed successfully.\n",
      "INFO:root:Creating Kafka producers...\n",
      "INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=ec2-54-80-241-235.compute-1.amazonaws.com:9092 <connecting> [IPv4 ('54.80.241.235', 9092)]>: connecting to ec2-54-80-241-235.compute-1.amazonaws.com:9092 [('54.80.241.235', 9092) IPv4]\n",
      "INFO:kafka.conn:Probing node bootstrap-0 broker version\n",
      "INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=ec2-54-80-241-235.compute-1.amazonaws.com:9092 <connecting> [IPv4 ('54.80.241.235', 9092)]>: Connection complete.\n",
      "INFO:kafka.conn:Broker version identified as 2.5.0\n",
      "INFO:kafka.conn:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup\n",
      "INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=ec2-54-80-241-235.compute-1.amazonaws.com:9092 <connecting> [IPv4 ('54.80.241.235', 9092)]>: connecting to ec2-54-80-241-235.compute-1.amazonaws.com:9092 [('54.80.241.235', 9092) IPv4]\n",
      "INFO:kafka.conn:Probing node bootstrap-0 broker version\n",
      "INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=ec2-54-80-241-235.compute-1.amazonaws.com:9092 <connecting> [IPv4 ('54.80.241.235', 9092)]>: Connection complete.\n",
      "INFO:kafka.conn:Broker version identified as 2.5.0\n",
      "INFO:kafka.conn:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup\n",
      "INFO:root:Connecting to PostgreSQL...\n",
      "INFO:root:PostgreSQL connection established successfully.\n",
      "INFO:root:Sent row 1 to PostgreSQL Kafka topic\n",
      "INFO:root:Sent row 1 to KServe Kafka topic\n",
      "INFO:kafka.conn:<BrokerConnection node_id=1 host=ec2-54-80-241-235.compute-1.amazonaws.com:9093 <connecting> [IPv4 ('54.80.241.235', 9093)]>: connecting to ec2-54-80-241-235.compute-1.amazonaws.com:9093 [('54.80.241.235', 9093) IPv4]\n",
      "INFO:kafka.conn:<BrokerConnection node_id=0 host=ec2-54-80-241-235.compute-1.amazonaws.com:9092 <connecting> [IPv4 ('54.80.241.235', 9092)]>: connecting to ec2-54-80-241-235.compute-1.amazonaws.com:9092 [('54.80.241.235', 9092) IPv4]\n",
      "INFO:kafka.conn:<BrokerConnection node_id=1 host=ec2-54-80-241-235.compute-1.amazonaws.com:9093 <connecting> [IPv4 ('54.80.241.235', 9093)]>: Connection complete.\n",
      "INFO:kafka.conn:<BrokerConnection node_id=0 host=ec2-54-80-241-235.compute-1.amazonaws.com:9092 <connecting> [IPv4 ('54.80.241.235', 9092)]>: Connection complete.\n",
      "INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=ec2-54-80-241-235.compute-1.amazonaws.com:9092 <connected> [IPv4 ('54.80.241.235', 9092)]>: Closing connection. \n",
      "INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=ec2-54-80-241-235.compute-1.amazonaws.com:9092 <connected> [IPv4 ('54.80.241.235', 9092)]>: Closing connection. \n",
      "INFO:root:Row 1 inserted into PostgreSQL successfully.\n",
      "INFO:root:Sent row 2 to PostgreSQL Kafka topic\n",
      "INFO:root:Sent row 2 to KServe Kafka topic\n",
      "INFO:root:Row 2 inserted into PostgreSQL successfully.\n",
      "INFO:root:Sent row 3 to PostgreSQL Kafka topic\n",
      "INFO:root:Sent row 3 to KServe Kafka topic\n",
      "INFO:root:Row 3 inserted into PostgreSQL successfully.\n",
      "INFO:root:Sent row 4 to PostgreSQL Kafka topic\n",
      "INFO:root:Sent row 4 to KServe Kafka topic\n",
      "INFO:root:Row 4 inserted into PostgreSQL successfully.\n",
      "INFO:root:Sent row 5 to PostgreSQL Kafka topic\n",
      "INFO:root:Sent row 5 to KServe Kafka topic\n",
      "INFO:root:Row 5 inserted into PostgreSQL successfully.\n",
      "INFO:kafka.producer.kafka:Closing the Kafka producer with 9223372036.0 secs timeout.\n",
      "INFO:kafka.conn:<BrokerConnection node_id=1 host=ec2-54-80-241-235.compute-1.amazonaws.com:9093 <connected> [IPv4 ('54.80.241.235', 9093)]>: Closing connection. \n",
      "INFO:kafka.producer.kafka:Closing the Kafka producer with 9223372036.0 secs timeout.\n",
      "INFO:kafka.conn:<BrokerConnection node_id=0 host=ec2-54-80-241-235.compute-1.amazonaws.com:9092 <connected> [IPv4 ('54.80.241.235', 9092)]>: Closing connection. \n",
      "INFO:root:First 5 rows sent to PostgreSQL Kafka topic: postgresql and KServe Kafka topic: three\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "from kafka import KafkaProducer\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Initialize logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Broker address\n",
    "brokers = [\"ec2-54-80-241-235.compute-1.amazonaws.com:9092\"]\n",
    "\n",
    "# GitHub raw URL for the CSV file\n",
    "github_url = \"https://raw.githubusercontent.com/tsimhadri-ews/internproject/malware-detection-0/src/MalwareData.csv\"\n",
    "\n",
    "# PostgreSQL database connection details\n",
    "db_config = {\n",
    "    'dbname': 'mydb',\n",
    "    'user': 'exampleuser',\n",
    "    'password': 'abc',\n",
    "    'host': '10.100.107.105',\n",
    "    'port': 5432\n",
    "}\n",
    "\n",
    "# Kafka topics\n",
    "postgres_topic = \"postgresql\"\n",
    "kserve_topic = \"three\"\n",
    "\n",
    "# Download the CSV file from GitHub\n",
    "logger.info(\"Downloading CSV file from GitHub...\")\n",
    "response = requests.get(github_url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    logger.info(\"CSV file downloaded successfully.\")\n",
    "    # Read the data into a pandas DataFrame\n",
    "    df = pd.read_csv(github_url, sep='|')\n",
    "    df = preprocess(df)\n",
    "    df = df.drop(columns=['legitimate'])\n",
    "    logger.info(\"CSV file processed successfully.\")\n",
    "else:\n",
    "    logger.error(f\"Failed to download file: {response.status_code}\")\n",
    "    exit()\n",
    "\n",
    "# Create Kafka producers\n",
    "logger.info(\"Creating Kafka producers...\")\n",
    "postgres_producer = KafkaProducer(\n",
    "    bootstrap_servers=brokers,\n",
    "    value_serializer=lambda message: json.dumps({k: str(v).lower() for k, v in message.items()}).encode('utf-8'),\n",
    ")\n",
    "\n",
    "kserve_producer = KafkaProducer(\n",
    "    bootstrap_servers=brokers,\n",
    "    value_serializer=lambda message: json.dumps(message).encode('utf-8'),\n",
    ")\n",
    "\n",
    "# PostgreSQL connection setup\n",
    "logger.info(\"Connecting to PostgreSQL...\")\n",
    "try:W\n",
    "    engine = create_engine(f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['dbname']}\")\n",
    "    logger.info(\"PostgreSQL connection established successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to connect to PostgreSQL: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Send data to KServe and PostgreSQL\n",
    "first_5_rows = df.head(5)\n",
    "for index, row in first_5_rows.iterrows():\n",
    "    data = row.to_dict()\n",
    "    \n",
    "    # Send to PostgreSQL topic\n",
    "    postgres_producer.send(postgres_topic, data)\n",
    "    logger.info(f\"Sent row {index + 1} to PostgreSQL Kafka topic\")\n",
    "    \n",
    "    # Send to KServe topic\n",
    "    kserve_producer.send(kserve_topic, data)\n",
    "    logger.info(f\"Sent row {index + 1} to KServe Kafka topic\")\n",
    "    \n",
    "    # Insert into PostgreSQL\n",
    "    try:\n",
    "        row_df = pd.DataFrame([data])\n",
    "        row_df.to_sql('your_table_name', engine, if_exists='append', index=False)\n",
    "        logger.info(f\"Row {index + 1} inserted into PostgreSQL successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to insert row {index + 1} into PostgreSQL: {e}\")\n",
    "\n",
    "# Flush data and close the producers\n",
    "postgres_producer.flush()\n",
    "postgres_producer.close()\n",
    "kserve_producer.flush()\n",
    "kserve_producer.close()\n",
    "logger.info(f\"First 5 rows sent to PostgreSQL Kafka topic: {postgres_topic} and KServe Kafka topic: {kserve_topic}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526481c5-2866-4b2c-8321-f139f155c33e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
