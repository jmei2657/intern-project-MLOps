{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87acfc4c-7766-44b5-9d05-5b3aeb06d38c",
   "metadata": {},
   "source": [
    "# Producer for Stream Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5184898-6e83-4602-abd2-469e69e1e731",
   "metadata": {},
   "source": [
    "## Installations and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3019287-4242-412c-ae4e-40e7537f2a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import boxcox\n",
    "import requests\n",
    "from kafka import KafkaProducer\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d92d748-8f4c-4530-869d-991d3e563e71",
   "metadata": {},
   "source": [
    "## Helper Functions for Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5e3f5f2-7800-4e1b-831a-789299287246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore_normalization(df, name):\n",
    "    mean = df[name].mean()\n",
    "    sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.drop(columns=['Name', 'md5'])\n",
    "    for i in df.columns:\n",
    "        if i != 'legitimate':\n",
    "            df[i] = boxcox(df[i], 0.5)\n",
    "            zscore_normalization(df, i)\n",
    "    correlation_matrix = df.corr()\n",
    "    cols_to_drop = []\n",
    "    for i in df.columns:\n",
    "        for j in df.columns:\n",
    "            if i != j and i != 'legitimate' and j != 'legitimate' and abs(correlation_matrix[i][j]) > 0.6 and i not in cols_to_drop and j not in cols_to_drop:\n",
    "                cols_to_drop.append(i)\n",
    "    cols_to_drop = set(cols_to_drop)\n",
    "    df.drop(columns=cols_to_drop, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2a51e8-a3f5-404e-8ffd-20b609ea3df9",
   "metadata": {},
   "source": [
    "## Producer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad69b93a-72e0-4fa8-8be8-93ba77f42788",
   "metadata": {},
   "source": [
    "### In this section the producer is created under the necessary broker, the data is extracted and preprocessed, serialized, and sent to the consumer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52b5da27-fc77-4409-a125-b8ee30d47bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:CSV file successfully downloaded and processed\n",
      "INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=ec2-184-73-88-208.compute-1.amazonaws.com:9092 <connecting> [IPv4 ('184.73.88.208', 9092)]>: connecting to ec2-184-73-88-208.compute-1.amazonaws.com:9092 [('184.73.88.208', 9092) IPv4]\n",
      "INFO:kafka.conn:Probing node bootstrap-0 broker version\n",
      "INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=ec2-184-73-88-208.compute-1.amazonaws.com:9092 <connecting> [IPv4 ('184.73.88.208', 9092)]>: Connection complete.\n",
      "INFO:kafka.conn:Broker version identified as 2.5.0\n",
      "INFO:kafka.conn:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup\n",
      "INFO:__main__:Kafka producer created successfully\n",
      "INFO:__main__:Streaming data in 2 batches of 3 rows each\n",
      "INFO:__main__:Sent row 1 to Kafka\n",
      "INFO:__main__:Sent row 2 to Kafka\n",
      "INFO:__main__:Sent row 3 to Kafka\n",
      "INFO:kafka.conn:<BrokerConnection node_id=1 host=ec2-184-73-88-208.compute-1.amazonaws.com:9093 <connecting> [IPv4 ('184.73.88.208', 9093)]>: connecting to ec2-184-73-88-208.compute-1.amazonaws.com:9093 [('184.73.88.208', 9093) IPv4]\n",
      "INFO:kafka.conn:<BrokerConnection node_id=1 host=ec2-184-73-88-208.compute-1.amazonaws.com:9093 <connecting> [IPv4 ('184.73.88.208', 9093)]>: Connection complete.\n",
      "INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=ec2-184-73-88-208.compute-1.amazonaws.com:9092 <connected> [IPv4 ('184.73.88.208', 9092)]>: Closing connection. \n",
      "ERROR:kafka.conn:<BrokerConnection node_id=1 host=ec2-184-73-88-208.compute-1.amazonaws.com:9093 <connected> [IPv4 ('184.73.88.208', 9093)]>: Error receiving network data closing socket\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/kafka/conn.py\", line 1090, in _recv\n",
      "    data = self._sock.recv(self.config['sock_chunk_bytes'])\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "INFO:kafka.conn:<BrokerConnection node_id=1 host=ec2-184-73-88-208.compute-1.amazonaws.com:9093 <connected> [IPv4 ('184.73.88.208', 9093)]>: Closing connection. KafkaConnectionError: [Errno 104] Connection reset by peer\n",
      "WARNING:kafka.client:Node 1 connection failed -- refreshing metadata\n",
      "WARNING:kafka.producer.record_accumulator:Produced messages to topic-partition TopicPartition(topic='testTopic', partition=0) with base offset -1 log start offset None and error None.\n",
      "WARNING:kafka.producer.record_accumulator:KafkaConnectionError: [Errno 104] Connection reset by peer\n",
      "INFO:kafka.conn:<BrokerConnection node_id=1 host=ec2-184-73-88-208.compute-1.amazonaws.com:9093 <connecting> [IPv4 ('184.73.88.208', 9093)]>: connecting to ec2-184-73-88-208.compute-1.amazonaws.com:9093 [('184.73.88.208', 9093) IPv4]\n",
      "INFO:kafka.conn:<BrokerConnection node_id=1 host=ec2-184-73-88-208.compute-1.amazonaws.com:9093 <connecting> [IPv4 ('184.73.88.208', 9093)]>: Connection complete.\n",
      "INFO:__main__:Batch 1/2 sent. Sleeping for 5 seconds.\n",
      "INFO:__main__:Sent row 4 to Kafka\n",
      "INFO:__main__:Sent row 5 to Kafka\n",
      "ERROR:kafka.conn:<BrokerConnection node_id=1 host=ec2-184-73-88-208.compute-1.amazonaws.com:9093 <connected> [IPv4 ('184.73.88.208', 9093)]>: Error receiving network data closing socket\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/kafka/conn.py\", line 1090, in _recv\n",
      "    data = self._sock.recv(self.config['sock_chunk_bytes'])\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "INFO:kafka.conn:<BrokerConnection node_id=1 host=ec2-184-73-88-208.compute-1.amazonaws.com:9093 <connected> [IPv4 ('184.73.88.208', 9093)]>: Closing connection. KafkaConnectionError: [Errno 104] Connection reset by peer\n",
      "WARNING:kafka.client:Node 1 connection failed -- refreshing metadata\n",
      "INFO:kafka.conn:<BrokerConnection node_id=1 host=ec2-184-73-88-208.compute-1.amazonaws.com:9093 <connecting> [IPv4 ('184.73.88.208', 9093)]>: connecting to ec2-184-73-88-208.compute-1.amazonaws.com:9093 [('184.73.88.208', 9093) IPv4]\n",
      "INFO:kafka.conn:<BrokerConnection node_id=1 host=ec2-184-73-88-208.compute-1.amazonaws.com:9093 <connecting> [IPv4 ('184.73.88.208', 9093)]>: Connection complete.\n",
      "INFO:kafka.conn:<BrokerConnection node_id=0 host=ec2-184-73-88-208.compute-1.amazonaws.com:9092 <connecting> [IPv4 ('184.73.88.208', 9092)]>: connecting to ec2-184-73-88-208.compute-1.amazonaws.com:9092 [('184.73.88.208', 9092) IPv4]\n",
      "INFO:kafka.conn:<BrokerConnection node_id=0 host=ec2-184-73-88-208.compute-1.amazonaws.com:9092 <connecting> [IPv4 ('184.73.88.208', 9092)]>: Connection complete.\n",
      "ERROR:kafka.conn:<BrokerConnection node_id=1 host=ec2-184-73-88-208.compute-1.amazonaws.com:9093 <connected> [IPv4 ('184.73.88.208', 9093)]>: Error receiving network data closing socket\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/kafka/conn.py\", line 1090, in _recv\n",
      "    data = self._sock.recv(self.config['sock_chunk_bytes'])\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "INFO:kafka.conn:<BrokerConnection node_id=1 host=ec2-184-73-88-208.compute-1.amazonaws.com:9093 <connected> [IPv4 ('184.73.88.208', 9093)]>: Closing connection. KafkaConnectionError: [Errno 104] Connection reset by peer\n",
      "WARNING:kafka.client:Node 1 connection failed -- refreshing metadata\n",
      "WARNING:kafka.producer.record_accumulator:Produced messages to topic-partition TopicPartition(topic='testTopic', partition=0) with base offset -1 log start offset None and error None.\n",
      "WARNING:kafka.producer.record_accumulator:KafkaConnectionError: [Errno 104] Connection reset by peer\n",
      "INFO:__main__:Batch 2/2 sent. Sleeping for 5 seconds.\n",
      "INFO:kafka.producer.kafka:Closing the Kafka producer with 9223372036.0 secs timeout.\n",
      "INFO:kafka.conn:<BrokerConnection node_id=0 host=ec2-184-73-88-208.compute-1.amazonaws.com:9092 <connected> [IPv4 ('184.73.88.208', 9092)]>: Closing connection. \n",
      "INFO:__main__:Kafka producer closed\n",
      "INFO:__main__:Data streamed to Kafka topic: testTopic in batches of 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Broker address\n",
    "brokers = [\"*:9092\"]\n",
    "\n",
    "# GitHub raw URL for the CSV file\n",
    "github_url = \"https://raw.githubusercontent.com/tsimhadri-ews/internproject/malware-detection-0/src/MalwareData.csv\"\n",
    "\n",
    "\n",
    "# Download the CSV file from GitHub\n",
    "response = requests.get(github_url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Read the data into a pandas DataFrame\n",
    "    df = pd.read_csv(github_url, sep='|')\n",
    "    df = preprocess(df)\n",
    "    df = df.drop(columns=['legitimate'])\n",
    "    df = df.head(5)\n",
    "    logger.info(\"CSV file successfully downloaded and processed\")\n",
    "else:\n",
    "    logger.error(f\"Failed to download file: {response.status_code}\")\n",
    "    exit()\n",
    "\n",
    "# Replace with your topic name\n",
    "topic = \"testTopic\"\n",
    "\n",
    "# Create a Kafka producer\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=brokers,\n",
    "    value_serializer=lambda message: json.dumps(message).encode('utf-8'),\n",
    ")\n",
    "logger.info(\"Kafka producer created successfully\")\n",
    "\n",
    "# Function to send data to Kafka in batches\n",
    "def stream_data_to_kafka(dataframe, batch_size, sleep_time):\n",
    "    num_batches = len(dataframe) // batch_size + (1 if len(dataframe) % batch_size != 0 else 0)\n",
    "    logger.info(f\"Streaming data in {num_batches} batches of {batch_size} rows each\")\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        start_index = i * batch_size\n",
    "        end_index = min((i + 1) * batch_size, len(dataframe))\n",
    "        \n",
    "        batch = dataframe.iloc[start_index:end_index]\n",
    "        \n",
    "        for index, row in batch.iterrows():\n",
    "            data = row.to_dict()\n",
    "            producer.send(topic, data)\n",
    "            logger.info(f\"Sent row {index + 1} to Kafka\")\n",
    "        \n",
    "        # Flush data to Kafka\n",
    "        producer.flush()\n",
    "        \n",
    "        # Sleep between batches\n",
    "        time.sleep(sleep_time)\n",
    "        logger.info(f\"Batch {i + 1}/{num_batches} sent. Sleeping for {sleep_time} seconds.\")\n",
    "    \n",
    "    # Close the producer after all batches are sent\n",
    "    producer.close()\n",
    "    logger.info(\"Kafka producer closed\")\n",
    "\n",
    "# Stream the data in batches of 5 rows with a 5-second interval between batches\n",
    "batch_size = 3\n",
    "sleep_time = 5  # seconds\n",
    "\n",
    "stream_data_to_kafka(df, batch_size, sleep_time)\n",
    "\n",
    "logger.info(f\"Data streamed to Kafka topic: {topic} in batches of {batch_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf77818-7c5b-462e-83f5-83174f089b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
