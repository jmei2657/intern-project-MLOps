{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84e14c01-3050-45b1-b4e3-a0deb63af111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kafka-python\n",
      "  Using cached kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)\n",
      "Installing collected packages: kafka-python\n",
      "Successfully installed kafka-python-2.0.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47c0d0d3-08a4-4810-ac60-68458abb847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "\n",
    "def get_secret():\n",
    "\n",
    "    secret_name = \"DBCreds\"\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "    \n",
    "    # Parse the secret string to get the credentials\n",
    "    secret_dict = json.loads(secret)\n",
    "    username = secret_dict['username']\n",
    "    password = secret_dict['password']\n",
    "    host = secret_dict['host']\n",
    "    port = secret_dict['port']\n",
    "    dbname = secret_dict['dbname']\n",
    "\n",
    "    return username, password, host, port, dbname\n",
    "\n",
    "\n",
    "(user,pswd,host,port,db) = get_secret()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1df2b5a-9625-4306-82c5-c6022964a50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Creating Kafka consumer...\n",
      "INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=52.200.168.233:9092 <connecting> [IPv4 ('52.200.168.233', 9092)]>: connecting to 52.200.168.233:9092 [('52.200.168.233', 9092) IPv4]\n",
      "INFO:kafka.conn:Probing node bootstrap-0 broker version\n",
      "INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=52.200.168.233:9092 <connecting> [IPv4 ('52.200.168.233', 9092)]>: Connection complete.\n",
      "INFO:kafka.conn:Broker version identified as 2.5.0\n",
      "INFO:kafka.conn:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup\n",
      "INFO:kafka.consumer.subscription_state:Updating subscribed topics to: ('three',)\n",
      "INFO:__main__:Subscribed to topic: three\n",
      "INFO:kafka.cluster:Group coordinator for my-group is BrokerMetadata(nodeId='coordinator-2', host='ec2-52-200-168-233.compute-1.amazonaws.com', port=9094, rack=None)\n",
      "INFO:kafka.coordinator:Discovered coordinator coordinator-2 for group my-group\n",
      "INFO:kafka.coordinator:Starting new heartbeat thread\n",
      "INFO:kafka.coordinator.consumer:Revoking previously assigned partitions set() for group my-group\n",
      "INFO:kafka.conn:<BrokerConnection node_id=coordinator-2 host=ec2-52-200-168-233.compute-1.amazonaws.com:9094 <connecting> [IPv4 ('52.200.168.233', 9094)]>: connecting to ec2-52-200-168-233.compute-1.amazonaws.com:9094 [('52.200.168.233', 9094) IPv4]\n",
      "INFO:kafka.conn:<BrokerConnection node_id=coordinator-2 host=ec2-52-200-168-233.compute-1.amazonaws.com:9094 <connecting> [IPv4 ('52.200.168.233', 9094)]>: Connection complete.\n",
      "INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=52.200.168.233:9092 <connected> [IPv4 ('52.200.168.233', 9092)]>: Closing connection. \n",
      "INFO:kafka.coordinator:(Re-)joining group my-group\n",
      "INFO:kafka.coordinator:Elected group leader -- performing partition assignments using range\n",
      "INFO:kafka.conn:<BrokerConnection node_id=2 host=ec2-52-200-168-233.compute-1.amazonaws.com:9094 <connecting> [IPv4 ('52.200.168.233', 9094)]>: connecting to ec2-52-200-168-233.compute-1.amazonaws.com:9094 [('52.200.168.233', 9094) IPv4]\n",
      "INFO:kafka.conn:<BrokerConnection node_id=2 host=ec2-52-200-168-233.compute-1.amazonaws.com:9094 <connecting> [IPv4 ('52.200.168.233', 9094)]>: Connection complete.\n",
      "INFO:kafka.coordinator:Successfully joined group my-group with generation 3\n",
      "INFO:kafka.consumer.subscription_state:Updated partition assignment: [TopicPartition(topic='three', partition=0)]\n",
      "INFO:kafka.coordinator.consumer:Setting newly assigned partitions {TopicPartition(topic='three', partition=0)} for group my-group\n",
      "INFO:kafka.conn:<BrokerConnection node_id=0 host=ec2-52-200-168-233.compute-1.amazonaws.com:9092 <connecting> [IPv4 ('52.200.168.233', 9092)]>: connecting to ec2-52-200-168-233.compute-1.amazonaws.com:9092 [('52.200.168.233', 9092) IPv4]\n",
      "INFO:kafka.conn:<BrokerConnection node_id=0 host=ec2-52-200-168-233.compute-1.amazonaws.com:9092 <connecting> [IPv4 ('52.200.168.233', 9092)]>: Connection complete.\n",
      "INFO:__main__:Consumer stopped manually.\n",
      "INFO:kafka.coordinator:Stopping heartbeat thread\n",
      "INFO:kafka.coordinator:Leaving consumer group (my-group).\n",
      "INFO:kafka.conn:<BrokerConnection node_id=coordinator-2 host=ec2-52-200-168-233.compute-1.amazonaws.com:9094 <connected> [IPv4 ('52.200.168.233', 9094)]>: Closing connection. \n",
      "INFO:kafka.conn:<BrokerConnection node_id=2 host=ec2-52-200-168-233.compute-1.amazonaws.com:9094 <connected> [IPv4 ('52.200.168.233', 9094)]>: Closing connection. \n",
      "INFO:kafka.conn:<BrokerConnection node_id=0 host=ec2-52-200-168-233.compute-1.amazonaws.com:9092 <connected> [IPv4 ('52.200.168.233', 9092)]>: Closing connection. \n",
      "ERROR:kafka.consumer.fetcher:Fetch to node 0 failed: Cancelled: <BrokerConnection node_id=0 host=ec2-52-200-168-233.compute-1.amazonaws.com:9092 <connected> [IPv4 ('52.200.168.233', 9092)]>\n",
      "INFO:__main__:Consumer closed.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from kafka import KafkaConsumer\n",
    "import requests\n",
    "import json\n",
    "import psycopg2\n",
    "import uuid\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "resp = []\n",
    "\n",
    "# Replace with your Kafka broker address(es)\n",
    "brokers = [f\"{host}:9092\"]\n",
    "\n",
    "# Replace with your topic name\n",
    "topic = \"three\"\n",
    "# KServe inference service URL\n",
    "kserve_url = 'http://dvc.kubeflow-user-example-com.svc.cluster.local/v1/models/dvc:predict'\n",
    "\n",
    "# Create a Kafka consumer\n",
    "logger.info(\"Creating Kafka consumer...\")\n",
    "consumer = KafkaConsumer(\n",
    "    topic,\n",
    "    bootstrap_servers=brokers,\n",
    "    auto_offset_reset='earliest',\n",
    "    enable_auto_commit=True,\n",
    "    group_id='my-group',\n",
    "    value_deserializer=lambda v: v.decode('utf-8')\n",
    ")\n",
    "\n",
    "logger.info(f\"Subscribed to topic: {topic}\")\n",
    "\n",
    "\n",
    "# Function to send data to KServe\n",
    "def send_to_kserve(data):\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    response = requests.post(kserve_url, headers=headers, data=json.dumps(data))\n",
    "    return response.json()\n",
    "\n",
    "def outcome_to_database(values):\n",
    "    db_details = {\n",
    "        'dbname': db,\n",
    "        'user': user,\n",
    "        'password': pswd,\n",
    "        'host': host,\n",
    "        'port': port\n",
    "    }\n",
    "    # Data to insert\n",
    "    outcome_data = {\n",
    "        'uid': values[0],  # Generating a unique ID\n",
    "        'outcome': values[1]  # This can be 0 or 1\n",
    "    }\n",
    "\n",
    "# Connect to PostgreSQL\n",
    "    try:\n",
    "        conn = psycopg2.connect(**db_details)\n",
    "        cursor = conn.cursor()\n",
    "        print(\"Connected to PostgreSQL successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to connect to PostgreSQL: {e}\")\n",
    "        exit()\n",
    "\n",
    "    # Insert data into the table\n",
    "    try:\n",
    "        insert_query = \"\"\"\n",
    "        INSERT INTO outcomes (uid, outcome)\n",
    "        VALUES (%s, %s)\n",
    "        \"\"\"\n",
    "        cursor.execute(insert_query, (outcome_data['uid'], outcome_data['outcome']))\n",
    "        conn.commit()\n",
    "        print(\"Data inserted successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to insert data: {e}\")\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if conn:\n",
    "            conn.close()\n",
    "        print(\"PostgreSQL connection closed.\")\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "try:\n",
    "    for message in consumer:\n",
    "        try:\n",
    "            resp = []\n",
    "            message = json.loads(message.value)  # Message value is already a dict\n",
    "            print(f\"Received message: {message}\")\n",
    "            uid = message.pop('uid', None)\n",
    "            resp.append(uid)\n",
    "            #print(f\"new message: {message}\")\n",
    "            # Prepare data for KServe\n",
    "            kserve_payload = {\n",
    "                \"instances\": [list(message.values())]  # Reshape the data to 2D array\n",
    "            }\n",
    "\n",
    "            # Send data to KServe\n",
    "            kserve_response = send_to_kserve(kserve_payload)\n",
    "            resp.append(kserve_response['predictions'][0])\n",
    "            print(f\"KServe response: {kserve_response}\")\n",
    "            print(resp)\n",
    "            outcome_to_database(resp)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Received non-JSON message: {message.value}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error sending to KServe: {e}\")\n",
    "        #logger.info(f\"Partition: {message.partition}, Offset: {message.offset}\")\n",
    "except KeyboardInterrupt:\n",
    "    logger.info(\"Consumer stopped manually.\")\n",
    "finally:\n",
    "    consumer.close()\n",
    "    logger.info(\"Consumer closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106a3e17-fa91-4ba2-aa97-165e9cdabb66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
